---
id: what_is_rucio
title: What is Rucio?
---

Having demonstrated very large scale data management capabilities, Don Quijote
(DQ2), the **ATLAS Distributed Data Management System** used for **HEP
experiments at CERN** had reached its limits in terms of scalability. The
primary concerns were

- the requirement of a large number of support staff to operate.
- difficulty in interfacing with new technologies

To address these very scaling requirements for HEP experiments, **Rucio** as a
Distributed Data Management System, was developed. Drawing benefits from
advances in Cloud & Big Data computations, it relies on a conceptual data model
to ensure system stability. Dataflow autonomy and automation are the key design
principles guiding the development of Rucio. To reduce the operational overheads
of the support staff, it employs an automation framework and also accounts for
newer use cases & user requirements of the LHC Run2 experiments.

## What can Rucio do

Standing on the shoulders of its predecessor, **ATLAS**, the capabilities of
Rucio are currently leveraged for:

- Storage of detector data, simulator data, and user data
- Unified interfacing of heterogenous network & storage infrastructure
- Support for newer protocols in Storage & Network using plugins
- Data Recovery
- Adaptive Replication
